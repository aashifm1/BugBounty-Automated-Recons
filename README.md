
# Bug Bounty - Recon Automation
> Developed for educational purposes only (use it ethically)

This repository contains automated shell scripts for recon in bug bounty hunting. The process is structured and takes input from a `targets.txt` file. These scripts are optimized for **wildcard** domains and designed to be run sequentially, where each step builds on the output of the previous one.

<img src="https://github.com/user-attachments/assets/024d46db-004a-4097-ae11-a4219e925c88"
     alt="automation"
     width="700"
     height="350">



## Step-by-Step Usage

### 1. Prepare your target list

Create a `targets.txt` file containing your target domains, one per line:

```bash
nano targets.txt
```



## Automation Process

Run the recon scripts in the following order. Each script uses output files generated by the previous step.



### Basic Recon (Level 1)

This script performs subdomain enumeration, live host checking, nuclei scanning, and wayback URL gathering.

```bash
bash basic.sh
```

**Output files:**

- `subdomains.txt` â€” Discovered subdomains
- `live.txt` â€” Live domains verified via HTTP
- `nuclei.txt` â€” Nuclei scan results (panels, takeovers, CVEs, exposures)
- `wayback.txt` â€” URLs fetched from Wayback Machine
- `params.txt` â€” URLs with parameters extracted from wayback URLs


### Advanced Recon (Level 2)

This script performs deep endpoint discovery, JavaScript secret hunting, parameter analysis with gf patterns, Dalfox XSS scanning, and header misconfiguration analysis.

```bash
bash advanced.sh
```

**Output files:**

- `deep-endpoints.txt` â€” Endpoints discovered via katana, hakrawler, and gau
- `jsfiles.txt` â€” JavaScript files extracted from wayback URLs
- `secret-js.txt` â€” Potential secrets found in JavaScript files
- `gf-xss.txt`, `gf-ssrf.txt`, `gf-redirect.txt` â€” Parameter filters using gf patterns
- `dalfox-xss.txt` â€” Dalfox XSS scan report
- `headers.txt` â€” HTTP header analysis for CORS, CSP, and other misconfigurations

Happy hunting! ðŸš€
